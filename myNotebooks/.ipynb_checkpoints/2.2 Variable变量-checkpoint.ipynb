{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Variable变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], requires_grad=True)\n",
      "tensor(7.5000)\n",
      "tensor(7.5000, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.FloatTensor([[1,2],[3,4]])\n",
    "v = Variable(tensor,requires_grad=True)\n",
    "\n",
    "print(tensor)\n",
    "print(v)\n",
    "\n",
    "t_out = torch.mean(tensor*tensor)\n",
    "v_out = torch.mean(v*v)\n",
    "\n",
    "print(t_out)\n",
    "print(v_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 反向传递求梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "v_out.backward()\n",
    "print(v.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.转换成numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "print(v.data) #是tensor的形式\n",
    "print(v.data.numpy()) #先变成tensor，再转换成numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注意：pytorch0.4之后的Torch类和Variable类合并，之后的代码按1.4版本写\n",
    "  \n",
    "#### 1. Variable可以使用，但返回的是Tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.FloatTensor([[1,2],[3,4]])\n",
    "v = Variable(tensor)\n",
    "\n",
    "print(tensor)\n",
    "print(v) #显示v是tensor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. requires_grad是Tensor的属性，默认是False："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default:  False\n",
      "after:  True\n",
      "set when created:  True\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2) \n",
    "print(\"default: \",a.requires_grad)\n",
    "a.requires_grad_(True) #设置requires_grad属性为true\n",
    "print(\"after: \",a.requires_grad)\n",
    "\n",
    "b=torch.randn(2,2,requires_grad=True) #创建时设置requires_grad属性为true\n",
    "print(\"set when created: \",b.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 用backward()求梯度\n",
    "注意：\n",
    "- 每次反向传播，梯度都会**累加**，因此反向传播之前要将梯度清零\n",
    "- 如果需要backward的tensor是张量，backward函数的参数是与其同型的tensor，tensor的值是每个数对应的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a.grad.data.zero_() #梯度清零\n",
    "b.grad.data.zero_()\n",
    "c = 2*a + b\n",
    "print(c.requires_grad) #a和b都是True，因此c为True\n",
    "tmp = torch.tensor([[1.,1.],[1.,1.]])\n",
    "c.backward(tmp) #传入和c同型的参数，值是权重\n",
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
